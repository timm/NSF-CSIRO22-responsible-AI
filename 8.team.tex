\newpage

\section{US-Australian Team}\label{sec:PriorResults}

This project will be conducted jointly between US and Australian teams including Prof. \textbf{Tim Menzies} from North Carolina State University in the US, and Associate Professor \textbf{Yulei Sui} and Distinguished Professor \textbf{CT Lin} from University of Technology Sydney in Australia.
This bilateral research collaboration (under the theme ``Responsible AI and Equitable AI'') aims to deliver transformative findings in the area of Responsible AI particularly focusing on building trustworthy foundations for deep learning.

%\section{Prior Results}
PI \textbf{Menzies} is an IEEE Fellow and has earned over \$13 million dollars in peer-reviewed competitive grants (\$6.4M from NSF, and  the rest for a variety of other government and industrial sources).
Google Scholar lists him as a top-ten researcher in many research areas including knowledge acquisition and analytics. Serving as committee chair, he has graduated 12 Ph.D. and 32 masters students (by research). He currently supervises 10 Ph.D. students at NC State. He has served as an associated editor on all the major SE journals and from 2021 will be EIC of the Automated Software Engineering journal. 


 We include below some notes  on some of his most recent NSF grants.

% PI Menzies is a co-PI with    Dr. Laurie Williams  working  on \underline{(a)}~CCF-1909516, 2019-2022, \$499,998; \underline{(b)}~``SHF: Small: Detecting the 1\%: Growing the Science of Vulnerability Detection''; \underline{(c)}~The {\bf intellectual merit} of that work was to explore characteristics of vulnerabilities with a focus on those that pose the highest security risk. The {\bf broader impact} of that work was to improve the ability of practitioners to produce secure software products so that people can rely upon computer systems to perform critical functions and to process, store, and communicate sensitive information securely. \underline{(d)}~That work has generated   journal articles (one at TSE), ICSE publications and one paper under review (at EMSE) \cite{yu2019improving,shu2019improved,elder2021structuring,shu2020omni}. \underline{(e)}~Data from that work is housed at the SEACRAFT publicly accessible repository~\cite{seacraft}. That work funded two Ph.D.s at NCSU. \underline{(f)} N/A.

PI Menzies worked on \underline{(a)}~CCF-1302216, 2013-2107, \$271,553; \underline{(b)}~``SHF: Medium: Collaborative: Transfer Learning in Software Engineering''; \underline{(c)}~The {\bf intellectual merit} of that work was to
define novel methods for sharing data, many of which were the precursor to the methods of this proposal.  That work generated the publications  \underline{(d)}~\cite{krishna2018bellwethers,peters2015lace2,he13,Me17,fu2016tuning,krishna2017learning,krishna2020whence} concerning prediction and planning methods.
The {\bf broader impact} of that work was to
enable a new kind of open science-- one where all data is routinely shared and is capable of building effective models no matter if it is obfuscated for security purposes.
The methods of this project, while targeted at software engineering, could also be applied to any other data-intensive field. \underline{(e)}~Data from that work is now housed in the two
publicly accessible repository\footnote{
{\bf github.com/rshu/Adversarial-Evasion-Defense}}. That work  funded two Ph.D.s at NCSU. \underline{(f)}
N/A. 


% One related data mining grant is \underline{(a)}~OAC-1931425, 2019-2022, \$592,129; \underline{(b)}~``Elements: Can Empirical SE be Adapted to Computational Science?''; \underline{(c)}~The {\bf intellectual merit} of that work was to create a workbench containing methods adapted from empirical software engineering, that would help bridge the skill gap via automatic agents by suggesting to developers when they should investigate or redo part of their code. The {\bf broader impact} is to reduce the associated cost (time, money, etc.) required to handle many of the large and more tedious aspects of software development. \underline{(d)}~That work generated one journal paper (at TSE), an MSR conference
% paper and two other papers under conference review~\cite{agrawal2018better,tu2021mining,tu2020changing}. \underline{(e)}~Data from that work is housed at the SEACRAFT publicly accessible repository~\cite{menzies2017seacraft}. That work funded one Ph.D. at NCSU. \underline{(f)} N/A.

Another relevant research grant is 
\underline{(a)}~OAC-1826574, 2018-2018, 
\$124,628.00;
\underline{(b)}~
``EAGER: Empirical Software Engineering for Computational Science'';
\underline{(c)}~ 
The {\bf intellectual merit} of that work was to
conduct initial explorations into novel methods for adapting SE methods to computational science.
That work lead to the curious
result that, in many ways,
the computational scientists are better
at managing their development cycle
than many SE projects~\cite{tu2020changing}. Whenever
we found good enough data to compare the results
seen in open source and computational
science projects, we often find higher productivity
values (and faster debugging) in computational science
than in software engineering. 
\underline{(d)}~That work generated 
one journal paper (at TSE'21),
one conference paper (at MSR'21) and another journal publication under review~\cite{Ling21}.
 \underline{(e)}~Data from that work is now housed at the SEACRAFT publicly accessible repository~\cite{menzies2017seacraft}. That work  funded one Ph.D. at NCSU. 
 \underline{(f)} N/A.  
 
\textbf{Yulei Sui} is currently working in the School of Computer Science at the University of Technology Sydney. 
He has been awarded an Australian Research Council Discovery Early Career Researcher Award (ARC DECRA) in 2017, and a 2022 JSPS Invitational Fellowship (mid-career to Professor level). 
He has earned over 2 million dollars (AUD) in peer-reviewed competitive grants including three ARC grants (\$ 1.5M) as the chief investigator and Australian Government grants (CSIRO/Data61 250K and CRC 400K) and many industry grants.
He is an expert in the area of software security analysis and trustworthy AI.
He has a sustained track record of research excellence as evidenced by the number of awards won at CORE-A/A* conferences over the past few years, as a PhD student (2013 CGO Best Paper Award), a postdoctoral research associate (2016 FSE Platinum Artifact), a DECRA fellow (2018 ICSE Distinguished Paper Award and 2019 SAS Best Paper Award) and more recently, as a balanced academic (ISSRE 2020 Best Paper Nominee and 2020 OOPSLA Distinguished Paper Award). His Field Weighted Citation Impact is 2.60 (years 2011-2021) well above the world average of 1.0 with over 90\% of his citations from the past five years. 
He is ranked 3rd in the world in the area of `Compiler Optimization; Program Analysis' based on his recent 5-year scholarly outputs (Scopus and SciVal), many of which have emerged as a result of his research leadership of his ARC DECRA project.


\textbf{CT Lin} is an IEEE Fellow and the Co-Director of Australian Artificial Intelligence Institute at UTS.  He is a leading researcher in AI and particularly the bio-inspired computation and brain computer interfaces (BCI), developing systems of brain information processing and communication with machines. Lin was the inventor of fuzzy neural networks (FNN) in 1992, introducing neural-network learning into fuzzy systems and incorporating human-like reasoning into neural networks.  Since then, there have been about 500,000 articles about FNN published online. Lin has since developed a series of FNN models with various learning capabilities suitable for different learning environments, as well as targets on multi-agent reinforcement learning for multi-drone coordination, human-AI teaming, and cybersecurity. He is a leading researcher in fuzzy reinforcement learning (FRL) by publishing the first FRL paper in 1994, which opens the research area of "expressible reinforcement learning" and leads to the expressible deep reinforcement learning nowadays.

CI Lin is ranked one of the 2021 Top 20 researchers in Computer Science and Electronics in Australia (Guide2Research). He is the most-cited author in Australia for three topics: FNN/fuzzy rules/radial basis function networks (and #3 worldwide). Lin’s citation metrics are exceptional for his career stage and for his discipline: h-index = 82; 30,369 citations; i10-index of 359 (Google Scholar). Lin’s 837 publications include 2 books; 28 book chapters; 395 original and internationally peer-reviewed journal papers; and 412 refereed conference papers. Of these, 78\% are authored with international collaborators from 5 continents. His field-weighted citation impact is 2.34, well above the world average of 1.0. Lin’s research has broad appeal. It has been mentioned 510+ times in social media, in the news and in blogs in 32 countries across 3 continents, sparking interest in the public, scientists and healthcare practitioners (Altmetric). His work has been mentioned 122 times in policy documents and patents. Lin publishes in top journals, for example, IEEE Transactions journals (182 papers), NeuroImage (11 papers) and Nature series journals (3 papers). He is also the Guest editor of IEEE Trans. on Fuzzy Systems on “Fuzzy Systems toward Human-Explainable AI in 2021.

Lin has served as the Chief Investigator (CI) of about 300 research projects funded by government and industries between 1992 and 2022. The total amount of research funding is approximately US\$42,765K (AUD\$53,469K). In particular, he served as the CI of several international large-scale research projects on intelligent systems, natural cognition, and brain-computer interface, spanning several countries and industries.



 \newpage
\include{kewen}
% See also 
% \underline{(a)}~CCF-1703487; 2017-2021,  \$898,349.00; 
% \underline{(b)}~SHF: Medium: Scalable Holistic Autotuning for Software Analytics; 
% \underline{(c)} The {\bf intellectual merit}
% of that work  was that there exist previously unexplored ``short-cuts'' in the search space of control parameters of data miners. The {\bf broader impact}
% was that better learners could be created
% automatically via ``hyperparameter optimizers''
% that exploited those short-cuts. This in term meant
% that anywhere these learners were deployed, they could
% be deployed again with {\em greater} effect. 
% \underline{(d)}~This work generated five journal
% articles at TSE, EMSE, IEEE Software,  
% and one other article currently under review at EMSE~\cite{yedida2021simple,agrawal2020simpler,Yedida21,DBLP:journals/ese/YangCYYM21,menzies2021shockingly,xia2019sequential};  \underline{(e)}~Data from that work is now housed at the SEACRAFT publicly accessible repository~\cite{menzies2017seacraft}. That work  funded two Ph.D. at NCSU.  \underline{(f)}~N/A.
 

  